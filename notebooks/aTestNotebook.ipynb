{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_221\"; Java(TM) SE Runtime Environment (build 1.8.0_221-b11); Java HotSpot(TM) 64-Bit Server VM (build 25.221-b11, mixed mode)\n",
      "  Starting server from /home/joci/anaconda3/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpm1wme2dt\n",
      "  JVM stdout: /tmp/tmpm1wme2dt/h2o_joci_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpm1wme2dt/h2o_joci_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54395\n",
      "Connecting to H2O server at http://127.0.0.1:54395... successful.\n",
      "Warning: Your H2O cluster version is too old (8 months and 28 days)! Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>06 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/GMT</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>8 months and 28 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_joci_xxnw72</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.755 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54395</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         06 secs\n",
       "H2O cluster timezone:       Etc/GMT\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.1\n",
       "H2O cluster version age:    8 months and 28 days !!!\n",
       "H2O cluster name:           H2O_from_python_joci_xxnw72\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.755 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  1\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54395\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.7.3 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "import subprocess\n",
    "#### subprocess.run('unset PYSPARK_SUBMIT_ARGS', shell=True)\n",
    "subprocess.run('export SPARK_LOCAL_IP=localhost ', shell=True)\n",
    "#\n",
    "sc = pyspark.SparkContext(appName=\"A Test 1 App\")\n",
    "sqlContext = SQLContext(sc)\n",
    "#\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "#####\n",
    "######## import subprocess\n",
    "######## subprocess.run('unset http_proxy', shell=True)\n",
    "####\n",
    "h2o.init(ip=\"localhost\",port=54321)\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asset: string (nullable = true)\n",
      " |-- device_os: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- asn: string (nullable = true)\n",
      " |-- isp: string (nullable = true)\n",
      " |-- start_time_unix_time: string (nullable = true)\n",
      " |-- startup_time_ms: string (nullable = true)\n",
      " |-- playing_time_ms: string (nullable = true)\n",
      " |-- buffering_time _ms: string (nullable = true)\n",
      " |-- interrupts: string (nullable = true)\n",
      " |-- average_bitrate_kbps: string (nullable = true)\n",
      " |-- startup error: string (nullable = true)\n",
      " |-- session_tags: string (nullable = true)\n",
      " |-- ip_address: string (nullable = true)\n",
      " |-- cdn: string (nullable = true)\n",
      " |-- browser: string (nullable = true)\n",
      " |-- conviva_session_id: string (nullable = true)\n",
      " |-- stream_url: string (nullable = true)\n",
      " |-- error_list: string (nullable = true)\n",
      " |-- percentage_complete: string (nullable = true)\n",
      "\n",
      "Data Load Done!\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "###\n",
    "### Input File in folder :  /data \n",
    "my_input_file=\"conviva11.csv\"\n",
    "###\n",
    "######\n",
    "##############################Execution##########################\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "\n",
    "import subprocess\n",
    "### subprocess.run('export SPARK_LOCAL_IP=0.0.0.0', shell=True)\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"IPTV-Anomaly-Detection-Conviva\")\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# import subprocess\n",
    "### subprocess.run('unset http_proxy', shell=True)\n",
    "## TEST IP\n",
    "### my_ip=\"localhost\" ## \"<<MY HOSTNAME DOESN'T WORK>>\" ##\n",
    "### h2o.init(ip=my_ip,port=54321)\n",
    "#\n",
    "#\n",
    "internal_predict_files=\"file:///home/joci/notebooks/data/\"+my_input_file\n",
    "#\n",
    "# Join with Internal Curation Data in urltopredict staged folder\n",
    "from pyspark.sql import functions as F\n",
    "### remove viewerID\n",
    "internaldata_df1=sqlContext.read.csv(internal_predict_files,header='true').drop(col('viewerId'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#\n",
    "internaldata_df1.printSchema()\n",
    "###\n",
    "####\n",
    "sc.stop()\n",
    "#\n",
    "print(\"Data Load Done!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
