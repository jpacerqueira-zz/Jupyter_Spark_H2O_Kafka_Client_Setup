{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "###### https://github.com/LucaCanali/Miscellaneous/blob/master/Pyspark_SQL_Magic_Jupyter/IPython_Pyspark_SQL_Magic.py\n",
    "#\n",
    "#\n",
    "# IPython magic functions to use with Pyspark and Spark SQL\n",
    "# The following code is intended as examples of shorcuts to simplify the use of SQL in pyspark\n",
    "# The defined functions are:\n",
    "#\n",
    "# %sql <statement>          - return a Spark DataFrame for lazy evaluation of the SQL\n",
    "# %sql_show <statement>     - run the SQL statement and show max_show_lines (50) lines\n",
    "# %sql_display <statement>  - run the SQL statement and display the results using a HTML table \n",
    "#                           - this is implemented passing via Pandas and displays up to max_show_lines (50)\n",
    "# %sql_explain <statement>  - display the execution plan of the SQL statement\n",
    "#\n",
    "# Use: %<magic> for line magic or %%<magic> for cell magic.\n",
    "#\n",
    "# Author: Luca.Canali@cern.ch\n",
    "# September 2016\n",
    "#\n",
    "\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "# Configuration parameters\n",
    "max_show_lines = 50         # Limit on the number of lines to show with %sql_show and %sql_display\n",
    "detailed_explain = True     # Set to False if you want to see only the physical plan when running explain\n",
    "\n",
    "\n",
    "@register_line_cell_magic\n",
    "def sql(line, cell=None):\n",
    "    \"Return a Spark DataFrame for lazy evaluation of the sql. Use: %sql or %%sql\"\n",
    "    val = cell if cell is not None else line \n",
    "    return sqlContext.sql(val)\n",
    "\n",
    "@register_line_cell_magic\n",
    "def sql_show(line, cell=None):\n",
    "    \"Execute sql and show the first max_show_lines lines. Use: %sql_show or %%sql_show\"\n",
    "    val = cell if cell is not None else line \n",
    "    return sqlContext.sql(val).show(max_show_lines) \n",
    "\n",
    "@register_line_cell_magic\n",
    "def sql_display(line, cell=None):\n",
    "    \"\"\"Execute sql and convert results to Pandas DataFrame for pretty display or further processing.\n",
    "    Use: %sql_display or %%sql_display\"\"\"\n",
    "    val = cell if cell is not None else line \n",
    "    return sqlContext.sql(val).limit(max_show_lines).toPandas() \n",
    "\n",
    "@register_line_cell_magic\n",
    "def sql_explain(line, cell=None):\n",
    "    \"Display the execution plan of the sql. Use: %sql_explain or %%sql_explain\"\n",
    "    val = cell if cell is not None else line \n",
    "    return sqlContext.sql(val).explain(detailed_explain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Real_Estate_Term: string (nullable = true)\n",
      " |-- Real_Estate_Definition: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "###### Load The Delta   ######\n",
    "##############################\n",
    "###\n",
    "### Input delta in folder :  /data \n",
    "my_input_delta_table=\"delta_real_estate_term_definitions\"\n",
    "###\n",
    "######\n",
    "##############################Execution##########################\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "import subprocess\n",
    "#\n",
    "sc = pyspark.SparkContext(appName=\"Business_Dictionary-Delta\")\n",
    "sqlContext = SQLContext(sc)\n",
    "#\n",
    "#\n",
    "internal_delta_files=\"file:///home/joci/notebooks/data/\"+my_input_delta_table\n",
    "#\n",
    "# Join with Internal Curation Data in urltopredict staged folder\n",
    "from pyspark.sql import functions as F\n",
    "### use version=1\n",
    "version=1\n",
    "## .option(\"versionAsOf\", version)\n",
    "delta_dataframe_df1=sqlContext.read.format(\"delta\").load(internal_delta_files)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#\n",
    "##.read.format(\"delta\").load(\"/delta/events\")\n",
    "#\n",
    "delta_dataframe_df1.printSchema()\n",
    "delta_dataframe_df1.registerTempTable(\"real_estate_terms\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+\n",
      "|    Real_Estate_Term|Real_Estate_Definition|\n",
      "+--------------------+----------------------+\n",
      "| Acceleration clause|  Also known as an ...|\n",
      "|   Active contingent|  When a seller acc...|\n",
      "|Active under cont...|  A house is listed...|\n",
      "|            Addendum|  If a buyer or sel...|\n",
      "|Adjustable-rate m...|  The interest rate...|\n",
      "|     Adjustment date|  This is the date ...|\n",
      "|        Amortization|  Amortization is t...|\n",
      "|Annual percentage...|  The annual percen...|\n",
      "|           Appraisal|  An appraisal on y...|\n",
      "|        Appreciation|  Appreciation is t...|\n",
      "|      Assessed value|  An assessment is ...|\n",
      "|          Assignment|  An assignment is ...|\n",
      "|  Assumable mortgage|  Assumption is whe...|\n",
      "|    Balloon mortgage|  Instead of a trad...|\n",
      "|  Bi-weekly mortgage|  A bi-weekly mortg...|\n",
      "|         Bridge loan|  A bridge loan is ...|\n",
      "|              Broker|  A broker has pass...|\n",
      "|             Buydown|  A buydown is a mo...|\n",
      "|         Call option|  A call option is ...|\n",
      "|  Cash-out refinance|  A cash-out refina...|\n",
      "+--------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sql_show\n",
    "select * from real_estate_terms limit 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------------+\n",
      "|Real_Estate_Term|Real_Estate_Definition|\n",
      "+----------------+----------------------+\n",
      "|          Broker|  A broker has pass...|\n",
      "+----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sql_show\n",
    "select * from real_estate_terms limit where Real_Estate_Term like 'Broker%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
