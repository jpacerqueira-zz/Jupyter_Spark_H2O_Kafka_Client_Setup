nohup: appending output to 'nohup.out'
[I 11:58:27.545 NotebookApp] JupyterLab extension loaded from /home/joci/anaconda3/lib/python3.7/site-packages/jupyterlab
[I 11:58:27.545 NotebookApp] JupyterLab application directory is /home/joci/anaconda3/share/jupyter/lab
[I 11:58:27.547 NotebookApp] Serving notebooks from local directory: /home/joci/notebooks
[I 11:58:27.547 NotebookApp] The Jupyter Notebook is running at:
[I 11:58:27.547 NotebookApp] http://(UKPC000117 or 127.0.0.1):9003/?token=d8e130487a10928af5097fc9fdc2b214bffdfb99d84809f5
[I 11:58:27.547 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 11:58:27.564 NotebookApp] 
    
    To access the notebook, open this file in a browser:
        file:///home/joci/.local/share/jupyter/runtime/nbserver-2282-open.html
    Or copy and paste one of these URLs:
        http://(UKPC000117 or 127.0.0.1):9003/?token=d8e130487a10928af5097fc9fdc2b214bffdfb99d84809f5
[I 11:58:51.658 NotebookApp] 302 POST /login?next=%2F (10.0.75.1) 13.63ms
[I 11:58:51.663 NotebookApp] 302 GET / (10.0.75.1) 0.51ms
[I 11:59:40.622 NotebookApp] Kernel started: 3c181337-e7bf-40c1-ab2c-9d926b9f5513
[I 11:59:42.929 NotebookApp] Adapting to protocol v5.1 for kernel 3c181337-e7bf-40c1-ab2c-9d926b9f5513
[I 12:00:16.859 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:00:47.447 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:00:58.383 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:01:02.019 NotebookApp] Starting buffering for 3c181337-e7bf-40c1-ab2c-9d926b9f5513:6b932fdd3a854c9f8ac184d1a5238ebc
[I 12:01:02.328 NotebookApp] Kernel shutdown: 3c181337-e7bf-40c1-ab2c-9d926b9f5513
[I 12:01:06.239 NotebookApp] Kernel started: 8a90f912-5278-4883-bac4-5efc01447036
[I 12:01:08.746 NotebookApp] Adapting to protocol v5.1 for kernel 8a90f912-5278-4883-bac4-5efc01447036
[I 12:01:20.280 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:01:54.834 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:02:01.581 NotebookApp] Saving file at /aTestNotebook.ipynb
Ivy Default Cache set to: /home/joci/.ivy2/cache
The jars for the packages stored in: /home/joci/.ivy2/jars
:: loading settings :: url = jar:file:/home/joci/spark/spark-2.4.3-bin-hadoop2.7/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
io.delta#delta-core_2.11 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-bd1b1a8f-964e-4ff3-9472-60adf03170eb;1.0
	confs: [default]
	found io.delta#delta-core_2.11;0.3.0 in central
:: resolution report :: resolve 324ms :: artifacts dl 5ms
	:: modules in use:
	io.delta#delta-core_2.11;0.3.0 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-bd1b1a8f-964e-4ff3-9472-60adf03170eb
	confs: [default]
	0 artifacts copied, 1 already retrieved (0kB/7ms)
19/08/07 11:02:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                         (0 + 4) / 50][Stage 2:==>                                                       (2 + 4) / 50][Stage 2:====>                                                     (4 + 4) / 50][Stage 2:======>                                                   (6 + 4) / 50][Stage 2:=========>                                                (8 + 4) / 50][Stage 2:=============>                                           (12 + 4) / 50][Stage 2:===============>                                         (14 + 4) / 50][Stage 2:==================>                                      (16 + 4) / 50][Stage 2:====================>                                    (18 + 4) / 50][Stage 2:=========================>                               (22 + 4) / 50][Stage 2:=============================>                           (26 + 4) / 50][Stage 2:=================================>                       (29 + 4) / 50][Stage 2:===================================>                     (31 + 4) / 50][Stage 2:=====================================>                   (33 + 4) / 50][Stage 2:=========================================>               (36 + 4) / 50][Stage 2:=============================================>           (40 + 4) / 50][Stage 2:===============================================>         (42 + 4) / 50][Stage 2:===================================================>     (45 + 4) / 50][Stage 3:>                                                          (0 + 1) / 1]                                                                                [I 12:03:06.039 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:03:58.489 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:04:05.451 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:04:25.474 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:05:06.025 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:05:06.805 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:05:16.616 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:05:55.750 NotebookApp] Saving file at /data/conviva11.csv
[I 12:06:12.754 NotebookApp] Saving file at /aTestNotebook.ipynb
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 12:06:49.661 NotebookApp] Saving file at /data/conviva11.csv
[I 12:07:00.530 NotebookApp] Saving file at /aTestNotebook.ipynb
[Stage 1:>                                                          (0 + 1) / 1]19/08/07 11:07:01 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/08/07 11:07:01 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
                                                                                [Stage 3:====>                                                     (4 + 4) / 50][Stage 3:=========>                                                (8 + 4) / 50][Stage 3:============>                                            (11 + 4) / 50][Stage 3:===============>                                         (14 + 4) / 50][Stage 3:===================>                                     (17 + 4) / 50][Stage 3:=======================>                                 (21 + 4) / 50][Stage 3:=============================>                           (26 + 4) / 50][Stage 3:==================================>                      (30 + 4) / 50][Stage 3:======================================>                  (34 + 4) / 50][Stage 3:============================================>            (39 + 4) / 50][Stage 3:==================================================>      (44 + 4) / 50][Stage 3:=======================================================> (49 + 1) / 50][Stage 4:>                                                          (0 + 1) / 1]                                                                                [I 12:08:18.497 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:08:46.259 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:08:51.406 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:10:11.810 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:10:18.894 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:11:04.650 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:12:14.952 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:12:30.421 NotebookApp] Saving file at /data/conviva11.csv
[I 12:13:06.071 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:14:44.059 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:14:54.460 NotebookApp] Saving file at /aTestNotebook.ipynb
[Stage 2:======>                                                   (6 + 4) / 51][Stage 2:============>                                            (11 + 4) / 51][Stage 2:=================>                                       (16 + 4) / 51][Stage 2:=========================>                               (23 + 4) / 51][Stage 2:=================================>                       (30 + 4) / 51][Stage 2:=======================================>                 (35 + 4) / 51][Stage 2:=================================================>       (44 + 4) / 51][Stage 2:=======================================================> (50 + 1) / 51][Stage 3:========>                                                 (7 + 4) / 50][Stage 3:=============>                                           (12 + 4) / 50][Stage 3:==================>                                      (16 + 4) / 50][Stage 3:=========================>                               (22 + 4) / 50][Stage 3:=============================>                           (26 + 4) / 50][Stage 3:===================================>                     (31 + 4) / 50][Stage 3:=========================================>               (36 + 4) / 50][Stage 3:==============================================>          (41 + 4) / 50][Stage 3:=====================================================>   (47 + 3) / 50][Stage 4:>                                                          (0 + 1) / 1]                                                                                [I 12:15:06.028 NotebookApp] Saving file at /aTestNotebook.ipynb
[W 12:15:25.567 NotebookApp] delete /data/delta_conviva
[Stage 2:=========>                                                (8 + 4) / 50][Stage 2:=============>                                           (12 + 4) / 50][Stage 2:===================>                                     (17 + 4) / 50][I 12:15:37.668 NotebookApp] Saving file at /aTestNotebook.ipynb
[Stage 2:=======================>                                 (21 + 4) / 50][Stage 2:=============================>                           (26 + 4) / 50][Stage 2:===================================>                     (31 + 4) / 50][Stage 2:=========================================>               (36 + 4) / 50][Stage 2:=================================================>       (43 + 4) / 50][Stage 2:=======================================================> (49 + 1) / 50][Stage 3:>                                                          (0 + 1) / 1]                                                                                19/08/07 11:15:40 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/08/07 11:15:40 WARN BlockManager: Block rdd_36_0 replicated to only 0 peer(s) instead of 1 peers
[Stage 4:>                                                          (0 + 1) / 1]                                                                                [Stage 6:======>                                                   (6 + 4) / 51][Stage 6:===========>                                             (10 + 4) / 51][Stage 6:====================>                                    (18 + 4) / 51][Stage 6:======================>                                  (20 + 4) / 51][Stage 6:================================>                        (29 + 4) / 51][Stage 6:========================================>                (36 + 4) / 51][Stage 6:================================================>        (43 + 4) / 51][Stage 6:=======================================================> (50 + 1) / 51][Stage 7:=====>                                                    (5 + 4) / 50][Stage 7:===========>                                             (10 + 4) / 50][Stage 7:=================>                                       (15 + 4) / 50][Stage 7:=====================>                                   (19 + 5) / 50][Stage 7:===========================>                             (24 + 4) / 50][Stage 7:===============================>                         (28 + 4) / 50][Stage 7:====================================>                    (32 + 4) / 50][Stage 7:==========================================>              (37 + 4) / 50][Stage 7:=============================================>           (40 + 4) / 50][Stage 7:==================================================>      (44 + 4) / 50][Stage 7:======================================================>  (48 + 2) / 50][Stage 8:>                                                          (0 + 1) / 1]                                                                                [I 12:16:04.722 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:16:05.647 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 12:17:43.405 NotebookApp] Starting buffering for 8a90f912-5278-4883-bac4-5efc01447036:e3bdb0bfeb4a4060b00e5803290a0a54
[I 12:25:24.485 NotebookApp] Adapting to protocol v5.1 for kernel 8a90f912-5278-4883-bac4-5efc01447036
[I 12:25:24.489 NotebookApp] Restoring connection for 8a90f912-5278-4883-bac4-5efc01447036:e3bdb0bfeb4a4060b00e5803290a0a54
[I 12:30:07.282 NotebookApp] Starting buffering for 8a90f912-5278-4883-bac4-5efc01447036:e3bdb0bfeb4a4060b00e5803290a0a54
[I 12:30:08.206 NotebookApp] Kernel shutdown: 8a90f912-5278-4883-bac4-5efc01447036
[I 12:30:54.466 NotebookApp] Kernel started: af398074-fdf1-4623-b580-db132b751094
[I 12:30:57.898 NotebookApp] Adapting to protocol v5.1 for kernel af398074-fdf1-4623-b580-db132b751094
[I 12:32:03.856 NotebookApp] Starting buffering for af398074-fdf1-4623-b580-db132b751094:38056d1ec59a4315aaea8d4239305820
[I 13:09:49.788 NotebookApp] Adapting to protocol v5.1 for kernel af398074-fdf1-4623-b580-db132b751094
[I 13:09:49.816 NotebookApp] Restoring connection for af398074-fdf1-4623-b580-db132b751094:38056d1ec59a4315aaea8d4239305820
[I 13:11:10.023 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 13:21:34.253 NotebookApp] Starting buffering for af398074-fdf1-4623-b580-db132b751094:38056d1ec59a4315aaea8d4239305820
[I 13:31:50.733 NotebookApp] Adapting to protocol v5.1 for kernel af398074-fdf1-4623-b580-db132b751094
[I 13:31:50.737 NotebookApp] Restoring connection for af398074-fdf1-4623-b580-db132b751094:38056d1ec59a4315aaea8d4239305820
[I 14:22:26.469 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 14:22:28.811 NotebookApp] Starting buffering for af398074-fdf1-4623-b580-db132b751094:38056d1ec59a4315aaea8d4239305820
[I 14:22:29.341 NotebookApp] Kernel shutdown: af398074-fdf1-4623-b580-db132b751094
[I 17:17:03.272 NotebookApp] Kernel started: 5bbce11c-c2df-4b1a-95de-6527a3c6549a
[I 17:17:07.017 NotebookApp] Adapting to protocol v5.1 for kernel 5bbce11c-c2df-4b1a-95de-6527a3c6549a
Ivy Default Cache set to: /home/joci/.ivy2/cache
The jars for the packages stored in: /home/joci/.ivy2/jars
:: loading settings :: url = jar:file:/home/joci/spark/spark-2.4.3-bin-hadoop2.7/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
io.delta#delta-core_2.11 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-1bcabb9e-583c-4e6f-9df3-f8a0d1f1b8bb;1.0
	confs: [default]
	found io.delta#delta-core_2.11;0.3.0 in central
:: resolution report :: resolve 347ms :: artifacts dl 4ms
	:: modules in use:
	io.delta#delta-core_2.11;0.3.0 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-1bcabb9e-583c-4e6f-9df3-f8a0d1f1b8bb
	confs: [default]
	0 artifacts copied, 1 already retrieved (0kB/7ms)
19/08/07 16:18:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                         (0 + 4) / 50][Stage 2:====>                                                     (4 + 4) / 50][Stage 2:======>                                                   (6 + 4) / 50][Stage 2:========>                                                 (7 + 4) / 50][Stage 2:===========>                                             (10 + 4) / 50][Stage 2:==============>                                          (13 + 4) / 50][Stage 2:=================>                                       (15 + 4) / 50][Stage 2:====================>                                    (18 + 4) / 50][Stage 2:=======================>                                 (21 + 4) / 50][Stage 2:============================>                            (25 + 4) / 50][Stage 2:===============================>                         (28 + 4) / 50][Stage 2:==================================>                      (30 + 4) / 50][Stage 2:======================================>                  (34 + 4) / 50][Stage 2:==========================================>              (37 + 4) / 50][Stage 2:==============================================>          (41 + 4) / 50][Stage 2:===================================================>     (45 + 4) / 50][Stage 3:>                                                          (0 + 1) / 1]                                                                                [Stage 5:==========>                                               (9 + 5) / 51][Stage 5:===============>                                         (14 + 4) / 51][Stage 5:======================>                                  (20 + 4) / 51][Stage 5:=============================>                           (26 + 4) / 51][Stage 5:======================================>                  (34 + 4) / 51][Stage 5:============================================>            (40 + 4) / 51][Stage 5:==================================================>      (45 + 4) / 51][Stage 5:=======================================================> (50 + 1) / 51][Stage 6:==>                                                       (2 + 4) / 50][Stage 6:=====>                                                    (5 + 4) / 50][Stage 6:==========>                                               (9 + 4) / 50][Stage 6:===============>                                         (14 + 4) / 50][Stage 6:===================>                                     (17 + 4) / 50][Stage 6:=========================>                               (22 + 4) / 50][Stage 6:==============================>                          (27 + 4) / 50][Stage 6:==================================>                      (30 + 4) / 50][Stage 6:=========================================>               (36 + 4) / 50][Stage 6:=============================================>           (40 + 4) / 50][Stage 6:==================================================>      (44 + 4) / 50][Stage 6:======================================================>  (48 + 2) / 50][Stage 7:>                                                          (0 + 1) / 1]                                                                                [Stage 8:>                                                          (0 + 1) / 1]19/08/07 16:18:50 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/08/07 16:18:50 WARN BlockManager: Block rdd_58_0 replicated to only 0 peer(s) instead of 1 peers
                                                                                [Stage 11:================>                                       (15 + 4) / 51][Stage 11:=======================>                                (21 + 4) / 51][Stage 11:===============================>                        (29 + 4) / 51][Stage 11:========================================>               (37 + 4) / 51][Stage 11:=================================================>      (45 + 4) / 51][Stage 12:=========>                                               (8 + 4) / 50][Stage 12:=============>                                          (12 + 4) / 50][Stage 12:====================>                                   (18 + 4) / 50][Stage 12:=========================>                              (23 + 4) / 50][Stage 12:=============================>                          (26 + 4) / 50][Stage 12:===================================>                    (32 + 4) / 50][Stage 12:========================================>               (36 + 4) / 50][Stage 12:=============================================>          (41 + 4) / 50][Stage 12:==================================================>     (45 + 4) / 50][Stage 13:>                                                         (0 + 1) / 1]                                                                                [I 17:19:03.003 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:21:03.009 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:21:20.934 NotebookApp] Saving file at /aTestNotebook.ipynb
19/08/07 16:21:24 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/08/07 16:21:24 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
[Stage 5:========>                                                 (7 + 4) / 50][Stage 5:===========>                                             (10 + 4) / 50][Stage 5:===============>                                         (14 + 4) / 50][Stage 5:====================>                                    (18 + 4) / 50][Stage 5:=========================>                               (22 + 4) / 50][Stage 5:===========================>                             (24 + 4) / 50][Stage 5:===============================>                         (28 + 4) / 50][Stage 5:====================================>                    (32 + 4) / 50][Stage 5:==========================================>              (37 + 4) / 50][Stage 5:==============================================>          (41 + 4) / 50][Stage 5:===================================================>     (45 + 4) / 50][Stage 5:=======================================================> (49 + 1) / 50][Stage 6:>                                                          (0 + 1) / 1]                                                                                [I 17:22:54.137 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:23:02.974 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:25:03.776 NotebookApp] Saving file at /aTestNotebook.ipynb
[W 17:25:35.911 NotebookApp] delete /data/delta_conviva/_delta_log/00000000000000000002.json
[W 17:25:51.981 NotebookApp] delete /data/delta_conviva/part-00000-9a7bb65e-449e-4239-840c-c42ea58c3c83-c000.snappy.parquet
[I 17:26:18.176 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:27:02.985 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:28:37.906 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:29:02.995 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:30:16.391 NotebookApp] Saving file at /aTestNotebook.ipynb
19/08/07 16:30:16 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/08/07 16:30:16 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
[Stage 1:>                                                          (0 + 1) / 1]                                                                                [W 17:30:55.244 NotebookApp] delete /data/delta_conviva
[I 17:31:02.985 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:31:23.777 NotebookApp] Saving file at /aTestNotebook.ipynb
[Stage 2:=========>                                                (8 + 4) / 50][Stage 2:=============>                                           (12 + 4) / 50][Stage 2:===============>                                         (14 + 6) / 50][Stage 2:=====================>                                   (19 + 4) / 50][Stage 2:===========================>                             (24 + 4) / 50][Stage 2:===============================>                         (28 + 4) / 50][Stage 2:=====================================>                   (33 + 4) / 50][Stage 2:==========================================>              (37 + 4) / 50][Stage 2:==============================================>          (41 + 4) / 50][Stage 2:=====================================================>   (47 + 3) / 50][Stage 3:>                                                          (0 + 1) / 1]                                                                                19/08/07 16:31:27 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/08/07 16:31:27 WARN BlockManager: Block rdd_36_0 replicated to only 0 peer(s) instead of 1 peers
[Stage 6:================>                                        (15 + 4) / 51][Stage 6:=============================>                           (26 + 4) / 51][Stage 6:=======================================>                 (35 + 4) / 51][Stage 6:===================================================>     (46 + 4) / 51][Stage 6:=======================================================> (50 + 1) / 51][Stage 7:===========>                                             (10 + 4) / 50][Stage 7:=================>                                       (15 + 4) / 50][Stage 7:=======================>                                 (21 + 4) / 50][Stage 7:==============================>                          (27 + 4) / 50][Stage 7:====================================>                    (32 + 4) / 50][Stage 7:===========================================>             (38 + 4) / 50][Stage 7:=================================================>       (43 + 4) / 50][Stage 7:=====================================================>   (47 + 3) / 50][Stage 8:>                                                          (0 + 1) / 1]                                                                                19/08/07 16:32:04 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/08/07 16:32:04 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
[Stage 4:>                                                         (0 + 4) / 50][Stage 4:====>                                                     (4 + 4) / 50][Stage 4:=========>                                                (8 + 4) / 50][Stage 4:===============>                                         (14 + 4) / 50][Stage 4:=====================>                                   (19 + 4) / 50][Stage 4:===========================>                             (24 + 4) / 50][Stage 4:===============================>                         (28 + 6) / 50][Stage 4:======================================>                  (34 + 4) / 50][Stage 4:===========================================>             (38 + 4) / 50][Stage 4:=================================================>       (43 + 4) / 50][Stage 4:======================================================>  (48 + 2) / 50][Stage 5:>                                                          (0 + 1) / 1]                                                                                [I 17:33:03.039 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:34:11.044 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:34:12.198 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:36:33.339 NotebookApp] Starting buffering for 5bbce11c-c2df-4b1a-95de-6527a3c6549a:62eddb80cd594c098c112aee160dd453
[I 17:36:34.464 NotebookApp] Kernel shutdown: 5bbce11c-c2df-4b1a-95de-6527a3c6549a
[I 17:36:36.438 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:36:45.049 NotebookApp] Kernel started: 37422a8c-7b80-4422-8e15-cfc6fc723600
[I 17:36:48.680 NotebookApp] Adapting to protocol v5.1 for kernel 37422a8c-7b80-4422-8e15-cfc6fc723600
Ivy Default Cache set to: /home/joci/.ivy2/cache
The jars for the packages stored in: /home/joci/.ivy2/jars
:: loading settings :: url = jar:file:/home/joci/spark/spark-2.4.3-bin-hadoop2.7/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
io.delta#delta-core_2.11 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-56fa2560-e2ff-4130-8dac-6e2d0a2d1a6d;1.0
	confs: [default]
	found io.delta#delta-core_2.11;0.3.0 in central
:: resolution report :: resolve 329ms :: artifacts dl 4ms
	:: modules in use:
	io.delta#delta-core_2.11;0.3.0 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-56fa2560-e2ff-4130-8dac-6e2d0a2d1a6d
	confs: [default]
	0 artifacts copied, 1 already retrieved (0kB/7ms)
19/08/07 16:37:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                         (0 + 4) / 50][Stage 2:>                                                         (0 + 5) / 50][Stage 2:====>                                                     (4 + 4) / 50][Stage 2:========>                                                 (7 + 4) / 50][Stage 2:==========>                                               (9 + 4) / 50][Stage 2:=============>                                           (12 + 4) / 50][Stage 2:===============>                                         (14 + 4) / 50][Stage 2:==================>                                      (16 + 4) / 50][Stage 2:======================>                                  (20 + 4) / 50][Stage 2:==========================>                              (23 + 4) / 50][Stage 2:==============================>                          (27 + 4) / 50][Stage 2:=================================>                       (29 + 4) / 50][Stage 2:====================================>                    (32 + 4) / 50][Stage 2:=======================================>                 (35 + 4) / 50][Stage 2:===========================================>             (38 + 4) / 50][Stage 2:===============================================>         (42 + 4) / 50][Stage 2:==================================================>      (44 + 4) / 50][Stage 2:======================================================>  (48 + 2) / 50][Stage 3:>                                                          (0 + 1) / 1]                                                                                [Stage 5:=======>                                                  (7 + 4) / 52][Stage 5:==============>                                          (13 + 4) / 52][Stage 5:====================>                                    (19 + 4) / 52][Stage 5:===========================>                             (25 + 4) / 52][Stage 5:=================================>                       (31 + 4) / 52][Stage 5:=========================================>               (38 + 4) / 52][Stage 5:================================================>        (44 + 4) / 52][Stage 5:======================================================>  (50 + 2) / 52][Stage 6:======>                                                   (6 + 4) / 50][Stage 6:==========>                                               (9 + 4) / 50][Stage 6:=============>                                           (12 + 4) / 50][Stage 6:==============>                                          (13 + 4) / 50][Stage 6:==================>                                      (16 + 4) / 50][Stage 6:=====================>                                   (19 + 4) / 50][Stage 6:==========================>                              (23 + 4) / 50][Stage 6:=============================>                           (26 + 4) / 50][Stage 6:==================================>                      (30 + 4) / 50][Stage 6:======================================>                  (34 + 4) / 50][Stage 6:============================================>            (39 + 4) / 50][Stage 6:==============================================>          (41 + 5) / 50][Stage 6:===================================================>     (45 + 4) / 50][Stage 6:=======================================================> (49 + 1) / 50][Stage 7:>                                                          (0 + 1) / 1]                                                                                [I 17:38:08.951 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:38:17.510 NotebookApp] Saving file at /aTestNotebook.ipynb
[Stage 1:>                                                          (0 + 1) / 1]19/08/07 16:38:17 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/08/07 16:38:17 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
                                                                                [Stage 4:=====>                                                    (5 + 4) / 50][Stage 4:=========>                                                (8 + 4) / 50][Stage 4:=============>                                           (12 + 4) / 50][Stage 4:=================>                                       (15 + 4) / 50][Stage 4:======================>                                  (20 + 4) / 50][Stage 4:=========================>                               (22 + 4) / 50][Stage 4:=============================>                           (26 + 4) / 50][Stage 4:==================================>                      (30 + 4) / 50][Stage 4:=====================================>                   (33 + 4) / 50][Stage 4:=========================================>               (36 + 4) / 50][Stage 4:===========================================>             (38 + 4) / 50][Stage 4:=============================================>           (40 + 4) / 50][Stage 4:=================================================>       (43 + 4) / 50][Stage 4:===================================================>     (45 + 4) / 50][Stage 4:======================================================>  (48 + 2) / 50][Stage 5:>                                                          (0 + 1) / 1]                                                                                [I 17:38:45.755 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 17:46:13.979 NotebookApp] Starting buffering for 37422a8c-7b80-4422-8e15-cfc6fc723600:a52543db7b064c938986b04e0eb47c7d
19/08/07 19:46:32 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:841)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:870)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:870)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:870)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:870)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
19/08/07 19:46:44 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:841)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:870)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:870)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:870)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:870)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
19/08/08 07:32:30 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:841)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:870)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:870)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:870)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:870)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
19/08/08 07:32:40 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:841)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:870)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:870)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:870)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:870)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
19/08/08 07:32:50 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from 0.0.0.0:51959 in 10000 milliseconds. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:216)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Failure.recover(Try.scala:216)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:44)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:252)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:157)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:36)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:63)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:78)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:54)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:601)
	at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:106)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:599)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:44)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:252)
	at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:157)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:206)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from 0.0.0.0:51959 in 10000 milliseconds
	... 8 more
19/08/08 07:32:52 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
19/08/08 07:32:52 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
19/08/08 07:32:52 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
19/08/08 07:32:52 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
19/08/08 07:32:52 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
[I 08:32:57.863 NotebookApp] Adapting to protocol v5.1 for kernel 37422a8c-7b80-4422-8e15-cfc6fc723600
[I 08:32:57.876 NotebookApp] Restoring connection for 37422a8c-7b80-4422-8e15-cfc6fc723600:a52543db7b064c938986b04e0eb47c7d
[I 09:04:45.639 NotebookApp] Adapting to protocol v5.1 for kernel 37422a8c-7b80-4422-8e15-cfc6fc723600
[I 09:05:45.254 NotebookApp] Kernel shutdown: 37422a8c-7b80-4422-8e15-cfc6fc723600
[I 09:06:34.753 NotebookApp] 302 POST /login?next=%2F (10.0.75.1) 28.28ms
[I 09:06:34.762 NotebookApp] 302 GET / (10.0.75.1) 3.61ms
