nohup: appending output to 'nohup.out'
[I 12:05:43.720 NotebookApp] JupyterLab extension loaded from /home/joci/anaconda3/lib/python3.7/site-packages/jupyterlab
[I 12:05:43.720 NotebookApp] JupyterLab application directory is /home/joci/anaconda3/share/jupyter/lab
[I 12:05:43.723 NotebookApp] Serving notebooks from local directory: /home/joci/notebooks
[I 12:05:43.723 NotebookApp] The Jupyter Notebook is running at:
[I 12:05:43.723 NotebookApp] http://(UKPC000117 or 127.0.0.1):9003/?token=54e63a05cae78eb3ba8ffca9666b076fbb93aec0bce1d967
[I 12:05:43.723 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 12:05:43.757 NotebookApp] 
    
    To access the notebook, open this file in a browser:
        file:///home/joci/.local/share/jupyter/runtime/nbserver-77-open.html
    Or copy and paste one of these URLs:
        http://(UKPC000117 or 127.0.0.1):9003/?token=54e63a05cae78eb3ba8ffca9666b076fbb93aec0bce1d967
[I 12:06:39.396 NotebookApp] 302 POST /login?next=%2F (10.0.75.1) 6.04ms
[I 12:06:39.407 NotebookApp] 302 GET / (10.0.75.1) 0.69ms
[I 12:07:48.436 NotebookApp] Kernel started: 06faef6d-1962-4ea8-9395-c6caa5d60e72
[I 12:07:50.809 NotebookApp] Adapting to protocol v5.1 for kernel 06faef6d-1962-4ea8-9395-c6caa5d60e72
19/07/26 11:08:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 1:>                                                          (0 + 1) / 1]19/07/26 11:08:43 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/07/26 11:08:43 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [I 12:09:48.866 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:11:48.295 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:13:48.420 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:15:48.278 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:17:48.190 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:19:50.377 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:23:48.383 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:51:48.261 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:51:48.424 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:51:49.718 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:51:52.543 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:52:30.261 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:52:33.524 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:52:55.712 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 12:53:25.698 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 15:30:37.854 NotebookApp] Starting buffering for 06faef6d-1962-4ea8-9395-c6caa5d60e72:018e9f530ea3491d8e696e1b8b5cc9d7
[I 15:49:38.180 NotebookApp] Adapting to protocol v5.1 for kernel 06faef6d-1962-4ea8-9395-c6caa5d60e72
[I 15:52:00.723 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 15:52:08.960 NotebookApp] Starting buffering for 06faef6d-1962-4ea8-9395-c6caa5d60e72:75c94aa31a054fe18754cb4cdddfa3da
[I 15:52:11.691 NotebookApp] Kernel shutdown: 06faef6d-1962-4ea8-9395-c6caa5d60e72
[I 15:52:17.506 NotebookApp] Kernel started: 59b603b0-6b3c-48e7-9a3c-29d094b3f6a6
[I 15:52:21.661 NotebookApp] Adapting to protocol v5.1 for kernel 59b603b0-6b3c-48e7-9a3c-29d094b3f6a6
[I 15:52:26.500 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
19/07/26 14:52:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 1:>                                                          (0 + 1) / 1]19/07/26 14:53:11 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/07/26 14:53:11 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
                                                                                [I 15:54:14.396 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 15:56:17.306 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 15:56:19.298 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 15:56:25.342 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 15:56:27.121 NotebookApp] Starting buffering for 59b603b0-6b3c-48e7-9a3c-29d094b3f6a6:31203333f9e6405d89b428bdaac465c8
[I 15:56:32.197 NotebookApp] Kernel shutdown: 59b603b0-6b3c-48e7-9a3c-29d094b3f6a6
[I 15:57:12.094 NotebookApp] Kernel started: 4a0dc7d7-4ece-499a-956f-a459bb92ab4d
[I 15:57:15.131 NotebookApp] Adapting to protocol v5.1 for kernel 4a0dc7d7-4ece-499a-956f-a459bb92ab4d
[I 15:58:02.310 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 15:58:19.939 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 15:58:31.403 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 15:58:43.711 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
19/07/26 14:58:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 15:59:11.894 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[Stage 1:>                                                          (0 + 1) / 1]19/07/26 14:59:20 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/07/26 14:59:20 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
                                                                                [I 16:01:11.901 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 16:03:11.909 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 16:05:11.939 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 16:07:11.959 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 16:09:12.083 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 16:11:12.039 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 16:15:11.917 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 16:23:11.993 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 16:25:11.905 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 16:25:45.313 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 16:35:58.576 NotebookApp] Starting buffering for 4a0dc7d7-4ece-499a-956f-a459bb92ab4d:8af92d341a334d2ca6dcb814a4aca8fa
[I 16:36:00.995 NotebookApp] Kernel shutdown: 4a0dc7d7-4ece-499a-956f-a459bb92ab4d
[I 08:45:45.971 NotebookApp] Kernel started: 49567caf-8741-4d03-881c-fc6919b65598
[I 08:45:50.914 NotebookApp] Adapting to protocol v5.1 for kernel 49567caf-8741-4d03-881c-fc6919b65598
[I 08:59:23.599 NotebookApp] Starting buffering for 49567caf-8741-4d03-881c-fc6919b65598:3307c1466c3348f09915d5acd3510d4a
[I 08:59:23.912 NotebookApp] Kernel shutdown: 49567caf-8741-4d03-881c-fc6919b65598
[I 09:30:42.625 NotebookApp] Kernel started: 4f0c6260-68de-496c-98d3-c5a7c3d14ab3
[I 09:30:46.242 NotebookApp] Adapting to protocol v5.1 for kernel 4f0c6260-68de-496c-98d3-c5a7c3d14ab3
[I 09:30:57.032 NotebookApp] Starting buffering for 4f0c6260-68de-496c-98d3-c5a7c3d14ab3:70e6b23603154bbd8a8a51fcc974952b
[I 09:31:01.543 NotebookApp] Kernel shutdown: 4f0c6260-68de-496c-98d3-c5a7c3d14ab3
[I 11:00:54.966 NotebookApp] Kernel started: d7398a70-9498-4190-a115-790f537c7c97
[I 11:01:06.074 NotebookApp] Adapting to protocol v5.1 for kernel d7398a70-9498-4190-a115-790f537c7c97
[I 12:06:22.758 NotebookApp] Starting buffering for d7398a70-9498-4190-a115-790f537c7c97:046f788a4d2c4b15aecb50cbb9760ec3
[I 12:06:23.602 NotebookApp] Kernel shutdown: d7398a70-9498-4190-a115-790f537c7c97
[I 13:35:41.091 NotebookApp] Kernel started: 4f7b4864-f535-480c-be42-805f1913e06b
[I 13:35:44.883 NotebookApp] Adapting to protocol v5.1 for kernel 4f7b4864-f535-480c-be42-805f1913e06b
[I 13:36:10.782 NotebookApp] 302 GET / (127.0.0.1) 3.95ms
[I 13:36:10.803 NotebookApp] 302 GET /tree? (127.0.0.1) 12.67ms
19/07/31 12:36:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]19/07/31 12:37:01 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/07/31 12:37:01 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
                                                                                [I 13:37:40.809 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 13:39:40.821 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 13:41:42.061 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 13:43:41.288 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 13:45:41.527 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 13:49:41.454 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 13:53:41.282 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:01:41.250 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:53:09.365 NotebookApp] Starting buffering for 4f7b4864-f535-480c-be42-805f1913e06b:afe246c301554c0a8663468d3ea070e9
[I 14:53:20.097 NotebookApp] Kernel shutdown: 4f7b4864-f535-480c-be42-805f1913e06b
[I 09:30:24.400 NotebookApp] 302 GET / (10.0.75.1) 14.15ms
[I 09:30:45.475 NotebookApp] Creating new directory in 
[I 09:31:04.501 NotebookApp] Creating new directory in /GoogleCloudPlatform
[I 09:31:22.250 NotebookApp] Uploading file to /GoogleCloudPlatform/DataProc-Training/PySpark-analysis-file (2).ipynb
[I 09:31:54.982 NotebookApp] Kernel started: ec9a1127-5211-43d1-ac42-74fbb892c04c
[I 09:31:58.094 NotebookApp] Adapting to protocol v5.1 for kernel ec9a1127-5211-43d1-ac42-74fbb892c04c
[I 09:32:11.383 NotebookApp] Starting buffering for ec9a1127-5211-43d1-ac42-74fbb892c04c:92c5abc28029462b8269c38d40181caf
[I 09:32:15.270 NotebookApp] Kernel shutdown: ec9a1127-5211-43d1-ac42-74fbb892c04c
[I 09:32:24.291 NotebookApp] Uploading file to /GoogleCloudPlatform/DataProc-Training/spark_analysis.py
[I 09:32:25.536 NotebookApp] Uploading file to /GoogleCloudPlatform/DataProc-Training/submit_onejob.sh
[I 09:32:47.826 NotebookApp] Kernel started: 401c3203-8097-43ae-996e-329e5a463b45
[I 09:32:50.107 NotebookApp] Adapting to protocol v5.1 for kernel 401c3203-8097-43ae-996e-329e5a463b45
[I 09:33:17.374 NotebookApp] Starting buffering for 401c3203-8097-43ae-996e-329e5a463b45:61affcdb06bf41549cc2e03691850e3d
[I 09:33:17.683 NotebookApp] Kernel shutdown: 401c3203-8097-43ae-996e-329e5a463b45
[I 09:33:19.417 NotebookApp] Saving file at /GoogleCloudPlatform/DataProc-Training/PySpark-analysis-file.ipynb
[I 10:14:44.377 NotebookApp] Uploading file to /GoogleCloudPlatform/DataProc-Training/Run_Migration_From_SparkSQL_to_BigQuery_usecase.ipynb
[I 10:17:20.588 NotebookApp] Kernel started: ed1e9d00-d77a-4f9d-9983-13381267f9be
[I 10:17:23.562 NotebookApp] Adapting to protocol v5.1 for kernel ed1e9d00-d77a-4f9d-9983-13381267f9be
[I 10:17:28.990 NotebookApp] Starting buffering for ed1e9d00-d77a-4f9d-9983-13381267f9be:2631a59c7aae4631945d420b4803004a
[I 10:17:33.917 NotebookApp] Kernel started: e6bbe6cf-de58-439d-a74c-b5d73d8ca75e
[I 10:17:36.198 NotebookApp] Adapting to protocol v5.1 for kernel e6bbe6cf-de58-439d-a74c-b5d73d8ca75e
[I 11:01:22.572 NotebookApp] Starting buffering for e6bbe6cf-de58-439d-a74c-b5d73d8ca75e:5b3027aeb650461b89fcfa3e8d740b33
[I 11:01:26.920 NotebookApp] Kernel shutdown: e6bbe6cf-de58-439d-a74c-b5d73d8ca75e
[I 11:01:27.239 NotebookApp] Kernel shutdown: ed1e9d00-d77a-4f9d-9983-13381267f9be
[I 11:01:35.898 NotebookApp] Uploading file to /GoogleCloudPlatform/DataProc-Training/05_functions.ipynb
[I 11:05:02.860 NotebookApp] Saving file at /GoogleCloudPlatform/DataProc-Training/05_functions.ipynb
[I 13:01:58.453 NotebookApp] Creating new directory in /GoogleCloudPlatform
[I 13:03:07.149 NotebookApp] Creating new directory in /GoogleCloudPlatform/CloudComposer-AirFlow
[I 13:03:33.134 NotebookApp] Uploading file to /GoogleCloudPlatform/CloudComposer-AirFlow/composer_https_post_example/spark_avg_speed.py
[I 13:03:34.136 NotebookApp] Uploading file to /GoogleCloudPlatform/CloudComposer-AirFlow/composer_https_post_example/README.md
[I 13:03:34.653 NotebookApp] Uploading file to /GoogleCloudPlatform/CloudComposer-AirFlow/composer_https_post_example/make_iap_request.py
[I 13:03:34.999 NotebookApp] Uploading file to /GoogleCloudPlatform/CloudComposer-AirFlow/composer_https_post_example/index.html.1
[I 13:03:35.316 NotebookApp] Uploading file to /GoogleCloudPlatform/CloudComposer-AirFlow/composer_https_post_example/index.html
[I 13:03:35.595 NotebookApp] Uploading file to /GoogleCloudPlatform/CloudComposer-AirFlow/composer_https_post_example/iap_requirements.txt
[I 13:03:35.909 NotebookApp] Uploading file to /GoogleCloudPlatform/CloudComposer-AirFlow/composer_https_post_example/ephemeral_dataproc_spark_dag.py
[I 13:03:36.260 NotebookApp] Uploading file to /GoogleCloudPlatform/CloudComposer-AirFlow/composer_https_post_example/dag_trigger.py
[I 13:03:36.644 NotebookApp] Uploading file to /GoogleCloudPlatform/CloudComposer-AirFlow/composer_https_post_example/airflow-ui.png
[I 13:03:36.991 NotebookApp] Uploading file to /GoogleCloudPlatform/CloudComposer-AirFlow/composer_https_post_example/__init__.py
[I 13:03:44.061 NotebookApp] Creating new directory in /GoogleCloudPlatform/CloudComposer-AirFlow/composer_https_post_example
[I 14:00:13.083 NotebookApp] Kernel started: 77555b8c-0115-4367-b24e-ffb43fb5970f
[I 14:00:16.443 NotebookApp] Adapting to protocol v5.1 for kernel 77555b8c-0115-4367-b24e-ffb43fb5970f
19/08/01 13:00:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 14:00:43.235 NotebookApp] 302 GET / (127.0.0.1) 0.75ms
[I 14:00:43.244 NotebookApp] 302 GET /tree? (127.0.0.1) 3.42ms
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]19/08/01 13:00:55 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/08/01 13:00:55 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
                                                                                [I 14:02:13.032 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:04:13.411 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:06:13.126 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:08:13.493 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:12:12.891 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:14:26.590 NotebookApp] Starting buffering for 77555b8c-0115-4367-b24e-ffb43fb5970f:c5e8da0842ad43ee8504bd2afb9e9a9c
[I 14:14:29.552 NotebookApp] Kernel shutdown: 77555b8c-0115-4367-b24e-ffb43fb5970f
[I 14:17:32.374 NotebookApp] Kernel started: 1c892962-4afa-4502-9f5e-ea5917ff479d
[I 14:17:35.283 NotebookApp] Adapting to protocol v5.1 for kernel 1c892962-4afa-4502-9f5e-ea5917ff479d
19/08/01 13:17:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]19/08/01 13:18:24 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/08/01 13:18:24 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
                                                                                [I 14:19:32.442 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:21:32.463 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:23:32.401 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:25:34.631 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:27:32.471 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:29:32.422 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:33:32.766 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:41:32.480 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 14:42:22.155 NotebookApp] 302 GET / (10.0.75.1) 16.28ms
[I 14:43:32.144 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 16:33:02.261 NotebookApp] Adapting to protocol v5.1 for kernel 1c892962-4afa-4502-9f5e-ea5917ff479d
[I 16:36:31.297 NotebookApp] Adapting to protocol v5.1 for kernel 1c892962-4afa-4502-9f5e-ea5917ff479d
[I 20:46:53.200 NotebookApp] Starting buffering for 1c892962-4afa-4502-9f5e-ea5917ff479d:804e55cb5aab4cecad360f3cca0fa0b9
[I 08:40:54.545 NotebookApp] Adapting to protocol v5.1 for kernel 1c892962-4afa-4502-9f5e-ea5917ff479d
[I 08:40:54.548 NotebookApp] Restoring connection for 1c892962-4afa-4502-9f5e-ea5917ff479d:804e55cb5aab4cecad360f3cca0fa0b9
[I 08:53:08.290 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 09:35:49.917 NotebookApp] Kernel started: bd163a56-2298-44f6-8174-c6527644da2a
[I 09:35:59.440 NotebookApp] Adapting to protocol v5.1 for kernel bd163a56-2298-44f6-8174-c6527644da2a
[I 09:36:46.334 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 09:37:10.331 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 09:37:13.345 NotebookApp] Starting buffering for 1c892962-4afa-4502-9f5e-ea5917ff479d:804e55cb5aab4cecad360f3cca0fa0b9
[I 09:37:14.887 NotebookApp] Kernel shutdown: 1c892962-4afa-4502-9f5e-ea5917ff479d
19/08/02 08:37:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 09:37:49.680 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 09:38:39.088 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 09:38:46.540 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 09:38:50.894 NotebookApp] Starting buffering for bd163a56-2298-44f6-8174-c6527644da2a:332726a5835e4bcdb2faac6d76ad9934
[I 09:38:51.835 NotebookApp] Kernel shutdown: bd163a56-2298-44f6-8174-c6527644da2a
[I 09:38:57.468 NotebookApp] Kernel started: 1dffca72-9cd6-420f-9770-16ceb92c90fa
[I 09:39:00.794 NotebookApp] Adapting to protocol v5.1 for kernel 1dffca72-9cd6-420f-9770-16ceb92c90fa
[I 09:39:18.515 NotebookApp] Saving file at /aTestNotebook.ipynb
19/08/02 08:39:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 09:39:48.191 NotebookApp] Saving file at /aTestNotebook.ipynb
19/08/02 08:40:04 WARN FileStreamSink: Error while looking for metadata directory.
[I 09:40:57.225 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 09:42:00.683 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 09:42:57.228 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 09:43:10.818 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 09:43:27.403 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 09:43:27.876 NotebookApp] Saving file at /aTestNotebook.ipynb
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 09:43:56.529 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 09:44:08.398 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 09:44:26.129 NotebookApp] Saving file at /aTestNotebook.ipynb
[I 09:44:27.850 NotebookApp] Starting buffering for 1dffca72-9cd6-420f-9770-16ceb92c90fa:bae9c004a11348549cdf617a2421e8a7
[I 09:44:28.466 NotebookApp] Kernel shutdown: 1dffca72-9cd6-420f-9770-16ceb92c90fa
[I 09:44:33.135 NotebookApp] Kernel started: 12ed8fc5-ab09-4d2b-8a03-d58bd4be2d44
[I 09:44:35.631 NotebookApp] Adapting to protocol v5.1 for kernel 12ed8fc5-ab09-4d2b-8a03-d58bd4be2d44
[I 09:44:38.779 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 09:45:04.261 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 09:45:16.058 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 09:45:20.258 NotebookApp] Starting buffering for 12ed8fc5-ab09-4d2b-8a03-d58bd4be2d44:46a612f8b74a467797d43ca786179452
[I 09:45:20.670 NotebookApp] Kernel shutdown: 12ed8fc5-ab09-4d2b-8a03-d58bd4be2d44
[W 10:03:03.436 NotebookApp] delete /data/prostate.csv
[I 10:03:08.375 NotebookApp] Creating new file in /data
[I 10:03:29.104 NotebookApp] Saving file at /data/prostate.csv
[I 10:03:41.471 NotebookApp] Copying IPTV_Anomaly_Detection_Conviva_Notebook.ipynb to 
[I 10:04:03.734 NotebookApp] Kernel started: 77a37788-babb-46eb-bb2a-7562f2f3fb4e
[I 10:04:07.898 NotebookApp] Adapting to protocol v5.1 for kernel 77a37788-babb-46eb-bb2a-7562f2f3fb4e
[I 10:04:57.499 NotebookApp] Saving file at /Prostate_Cancer_Predictor.ipynb
[I 10:05:04.972 NotebookApp] Saving file at /Prostate_Cancer_Predictor.ipynb
[I 10:05:18.540 NotebookApp] Saving file at /Prostate_Cancer_Predictor.ipynb
19/08/02 09:05:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 10:06:07.997 NotebookApp] Saving file at /Prostate_Cancer_Predictor.ipynb
[Stage 0:===========================================================(1 + 0) / 1]                                                                                19/08/02 09:06:14 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/08/02 09:06:14 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
[Stage 1:>                                                          (0 + 1) / 1]                                                                                [I 10:07:16.095 NotebookApp] Saving file at /Prostate_Cancer_Predictor.ipynb
[I 10:07:17.692 NotebookApp] Starting buffering for 77a37788-babb-46eb-bb2a-7562f2f3fb4e:84ddd2b352bd4364838bf58d4d453b93
[I 10:07:18.723 NotebookApp] Kernel shutdown: 77a37788-babb-46eb-bb2a-7562f2f3fb4e
[I 10:07:24.990 NotebookApp] Kernel started: b12af1b3-9120-4b6e-9cd7-e1a1d4110da7
[I 10:07:27.640 NotebookApp] Adapting to protocol v5.1 for kernel b12af1b3-9120-4b6e-9cd7-e1a1d4110da7
[I 10:07:28.835 NotebookApp] Saving file at /Prostate_Cancer_Predictor.ipynb
19/08/02 09:07:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
19/08/02 09:07:36 WARN JettyUtils: GET /jobs/ failed: java.util.NoSuchElementException
java.util.NoSuchElementException
	at java.util.Collections$EmptyIterator.next(Collections.java:4191)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryIterator.next(InMemoryStore.java:281)
	at org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:38)
	at org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:275)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:84)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:84)
	at org.apache.spark.ui.JettyUtils$$anon$3.doGet(JettyUtils.scala:90)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:539)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)
19/08/02 09:07:36 WARN ServletHandler: /jobs/
java.util.NoSuchElementException
	at java.util.Collections$EmptyIterator.next(Collections.java:4191)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryIterator.next(InMemoryStore.java:281)
	at org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:38)
	at org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:275)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:84)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:84)
	at org.apache.spark.ui.JettyUtils$$anon$3.doGet(JettyUtils.scala:90)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:539)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)
19/08/02 09:07:37 WARN JettyUtils: GET /jobs/ failed: java.util.NoSuchElementException
java.util.NoSuchElementException
	at java.util.Collections$EmptyIterator.next(Collections.java:4191)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryIterator.next(InMemoryStore.java:281)
	at org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:38)
	at org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:275)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:84)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:84)
	at org.apache.spark.ui.JettyUtils$$anon$3.doGet(JettyUtils.scala:90)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:539)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)
19/08/02 09:07:37 WARN ServletHandler: /jobs/
java.util.NoSuchElementException
	at java.util.Collections$EmptyIterator.next(Collections.java:4191)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryIterator.next(InMemoryStore.java:281)
	at org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:38)
	at org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:275)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:84)
	at org.apache.spark.ui.WebUI$$anonfun$2.apply(WebUI.scala:84)
	at org.apache.spark.ui.JettyUtils$$anon$3.doGet(JettyUtils.scala:90)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.spark_project.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:584)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:539)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)
[Stage 0:>                                                          (0 + 1) / 1]                                                                                19/08/02 09:08:04 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/08/02 09:08:04 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
[I 10:09:14.425 NotebookApp] Saving file at /Prostate_Cancer_Predictor.ipynb
[I 10:12:36.926 NotebookApp] Saving file at /Prostate_Cancer_Predictor.ipynb
[I 10:17:24.754 NotebookApp] Saving file at /Prostate_Cancer_Predictor.ipynb
[I 10:18:27.066 NotebookApp] Saving file at /Prostate_Cancer_Predictor.ipynb
[I 10:32:34.646 NotebookApp] Starting buffering for b12af1b3-9120-4b6e-9cd7-e1a1d4110da7:2b4d5e0eaecf4fc4b6b3eeeca2929b30
[I 10:32:35.777 NotebookApp] Kernel shutdown: b12af1b3-9120-4b6e-9cd7-e1a1d4110da7
[I 15:38:58.049 NotebookApp] Kernel started: 088aaadf-f364-4701-8484-c63be895bed6
[I 15:39:02.760 NotebookApp] Adapting to protocol v5.1 for kernel 088aaadf-f364-4701-8484-c63be895bed6
[I 16:12:03.516 NotebookApp] Saving file at /Prostate_Cancer_Predictor.ipynb
[I 17:56:52.923 NotebookApp] Starting buffering for 088aaadf-f364-4701-8484-c63be895bed6:ceaa61fd4f934eeb8cc4b78f06626b85
[I 17:57:10.793 NotebookApp] Kernel shutdown: 088aaadf-f364-4701-8484-c63be895bed6
[I 17:57:13.991 NotebookApp] Kernel started: 58c87d7f-cd8d-453b-bc79-018166cd4611
[I 17:57:17.109 NotebookApp] Adapting to protocol v5.1 for kernel 58c87d7f-cd8d-453b-bc79-018166cd4611
[I 17:57:21.161 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
19/08/02 16:57:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]19/08/02 16:58:17 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
19/08/02 16:58:17 WARN BlockManager: Block rdd_11_0 replicated to only 0 peer(s) instead of 1 peers
                                                                                [I 17:59:14.643 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 18:01:14.613 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 18:03:14.636 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 18:05:20.220 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 18:07:18.368 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 18:11:14.813 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 18:15:13.816 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 18:15:19.540 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 18:15:20.560 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 18:15:21.576 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 18:23:13.737 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 18:24:35.836 NotebookApp] Saving file at /IPTV_Anomaly_Detection_Conviva_Notebook.ipynb
[I 18:24:38.946 NotebookApp] Starting buffering for 58c87d7f-cd8d-453b-bc79-018166cd4611:de340d334e3a4bdf91668338c7163fb9
[I 18:24:40.372 NotebookApp] Kernel shutdown: 58c87d7f-cd8d-453b-bc79-018166cd4611
