{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_221\"; Java(TM) SE Runtime Environment (build 1.8.0_221-b11); Java HotSpot(TM) 64-Bit Server VM (build 25.221-b11, mixed mode)\n",
      "  Starting server from /home/joci/anaconda3/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmp4q5g3inn\n",
      "  JVM stdout: /tmp/tmp4q5g3inn/h2o_joci_started_from_python.out\n",
      "  JVM stderr: /tmp/tmp4q5g3inn/h2o_joci_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n",
      "Warning: Your H2O cluster version is too old (9 months and 11 days)! Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/GMT</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>9 months and 11 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_joci_1fb9d6</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.755 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         03 secs\n",
       "H2O cluster timezone:       Etc/GMT\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.1\n",
       "H2O cluster version age:    9 months and 11 days !!!\n",
       "H2O cluster name:           H2O_from_python_joci_1fb9d6\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.755 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  1\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.7.3 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.files.SparkFiles'>\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "from pyspark import SparkFiles as spf\n",
    "#\n",
    "import subprocess\n",
    "#### subprocess.run('unset PYSPARK_SUBMIT_ARGS', shell=True)\n",
    "subprocess.run('export SPARK_LOCAL_IP=localhost ', shell=True)\n",
    "#\n",
    "### DELTA Runtime start script \n",
    "##### subprocess.run('export PACKAGES=\"io.delta:delta-core_2.11:0.3.0\" ', shell=True)\n",
    "##### subprocess.run('export PYSPARK_SUBMIT_ARGS=\"--packages ${PACKAGES} ${PYSPARK_SUBMIT_ARGS}\" ', shell=True)\n",
    "####\n",
    "####\n",
    "sc = pyspark.SparkContext(appName=\"A Test 1 App\") \n",
    "sqlContext = SQLContext(sc)\n",
    "#\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "#####\n",
    "######## import subprocess\n",
    "######## subprocess.run('unset http_proxy', shell=True)\n",
    "####\n",
    "h2o.init(ip=\"localhost\",port=54321)\n",
    "#\n",
    "#\n",
    "sparkfiles=spf.getRootDirectory()\n",
    "print(spf)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NCOL: string (nullable = true)\n",
      " |-- Real_Estate_Terms_and_Definitions: string (nullable = true)\n",
      "\n",
      "+----+---------------------------------+\n",
      "|NCOL|Real_Estate_Terms_and_Definitions|\n",
      "+----+---------------------------------+\n",
      "|null|              Acceleration clause|\n",
      "|null|             Also known as an ...|\n",
      "|null|                             null|\n",
      "|null|                Active contingent|\n",
      "|null|             When a seller acc...|\n",
      "|null|                             null|\n",
      "|null|             Active under cont...|\n",
      "|null|             A house is listed...|\n",
      "+----+---------------------------------+\n",
      "only showing top 8 rows\n",
      "\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Real_Estate_Terms_and_Definitions                                                                                                                                                                                                                                                                                 |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Acceleration clause                                                                                                                                                                                                                                                                                               |\n",
      "|Also known as an acceleration covenant, this is a contract provision requiring the borrower to repay all of their outstanding loan to a lender if certain requirements -- outlined by the lender -- aren’t met.                                                                                                   |\n",
      "|Active contingent                                                                                                                                                                                                                                                                                                 |\n",
      "|When a seller accepts an offer from a buyer, that offer is contingent upon the buyer’s ability to meet certain conditions before finalization of the sale. Contingencies might include the buyer selling their home, receiving mortgage approval, or reaching an agreement with the seller on the home inspection.|\n",
      "|Active under contract                                                                                                                                                                                                                                                                                             |\n",
      "|A house is listed as “active under contract” when the seller has accepted an offer with contingencies, but still wants the house to be listed as active. In this situation, the seller is also likely accepting backup offers in case their current offer fails to meet its contingencies.                        |\n",
      "|Addendum                                                                                                                                                                                                                                                                                                          |\n",
      "|If a buyer or seller want to change an existing contract, they might add an addendum outlining the specific part of the contract they’d like to adjust and the parameters of that change. The rest of the contract stays the same, regardless of the addendum.                                                    |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 8 rows\n",
      "\n",
      "Data Load Done!\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "###\n",
    "### Input File in folder :  /data \n",
    "my_input_file=\"business_terms.csv\"\n",
    "###\n",
    "######\n",
    "##############################Execution##########################\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "import subprocess\n",
    "### subprocess.run('export SPARK_LOCAL_IP=0.0.0.0', shell=True)\n",
    "#\n",
    "sc = pyspark.SparkContext(appName=\"Business_Dictionary-Delta\")\n",
    "sqlContext = SQLContext(sc)\n",
    "#\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "#\n",
    "import subprocess\n",
    "#\n",
    "### DELTA Runtime start script \n",
    "##### subprocess.run('export PACKAGES=\"io.delta:delta-core_2.11:0.3.0\" ', shell=True)\n",
    "##### subprocess.run('export PYSPARK_SUBMIT_ARGS=\"--packages ${PACKAGES} ${PYSPARK_SUBMIT_ARGS}\" ', shell=True)\n",
    "####\n",
    "### subprocess.run('unset http_proxy', shell=True)\n",
    "## TEST IP\n",
    "### my_ip=\"localhost\" ## \"<<MY HOSTNAME DOESN'T WORK>>\" ##\n",
    "### h2o.init(ip=my_ip,port=54321)\n",
    "#\n",
    "#\n",
    "internal_predict_files=\"file:///home/joci/notebooks/data/\"+my_input_file\n",
    "#\n",
    "# Join with Internal Curation Data in urltopredict staged folder\n",
    "from pyspark.sql import functions as F\n",
    "### remove viewerID\n",
    "internaldata_df1=sqlContext.read.csv(internal_predict_files,header='true')\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#\n",
    "#\n",
    "internaldata_df1.printSchema()\n",
    "#\n",
    "internaldata_df1.show(8)\n",
    "#\n",
    "df1=internaldata_df1.drop(col('NCOL')).filter(\"Real_Estate_Terms_and_Definitions IS NOT NULL\")\\\n",
    ".select(\"Real_Estate_Terms_and_Definitions as Real_Estate_Term,Real_Estate_Terms_and_Definitions as Real_Estate_Definition \")\n",
    ".\n",
    "#\n",
    "df1.show(8,0)\n",
    "#\n",
    "df1.write.format(\"delta\").save(\"file:///home/joci/notebooks/data/delta_business_terms/\")\n",
    "###\n",
    "####\n",
    "sc.stop()\n",
    "#\n",
    "print(\"Data Load Done!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
