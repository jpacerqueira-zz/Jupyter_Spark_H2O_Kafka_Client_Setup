{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "\n",
    "import subprocess\n",
    "### subprocess.run('export SPARK_LOCAL_IP=0.0.0.0', shell=True)\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"IPTV-Anomaly-Detection-Conviva\")\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# import subprocess\n",
    "### subprocess.run('unset http_proxy', shell=True)\n",
    "\n",
    "h2o.init(ip=\"localhost\",port=54321)\n",
    "#\n",
    "#\n",
    "#\n",
    "internal_predict_files=\"file:///home/joci/notebooks/data/conviva11.csv\"\n",
    "#\n",
    "# Join with Internal Curation Data in urltopredict staged folder\n",
    "from pyspark.sql import functions as F\n",
    "### remove viewerID\n",
    "internaldata_df1=sqlContext.read.csv(internal_predict_files,header='true').drop(col('viewerId'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#\n",
    "internaldata_df1.printSchema()\n",
    "###\n",
    "###\n",
    "#\n",
    "train_pd=internaldata_df1.toPandas()\n",
    "test_pd=internaldata_df1.toPandas().head(300)                                                                        \n",
    "train=h2o.H2OFrame(train_pd)\n",
    "test=h2o.H2OFrame(test_pd)\n",
    "#\n",
    "##\n",
    "###### TRAINING PROCESS ############\n",
    "# RBIND \"Merge\" all of 3 internal ccrawl and phishtank with rbind .\n",
    "# function merge() doesn't work if both H2O/dataframes have same variables\n",
    "#\n",
    "### train = train_hf1.rbind(train_hf2)\n",
    "### test = test_hf1.rbind(test_hf2)\n",
    "#\n",
    "#\n",
    "print(\"train\")\n",
    "print(train.head(10))\n",
    "print(\"test\")\n",
    "print(test.head(10))\n",
    "#\n",
    "#\n",
    "# Identify predictors and response\n",
    "x = train.columns\n",
    "#\n",
    "# test Learning is it a bit URL TRUE/FALSE\n",
    "#y = 'massiveurl'\n",
    "#\n",
    "# Classify and discovery for Average BitRate\n",
    "#\n",
    "y= 'average_bitrate_kbps'\n",
    "#\n",
    "x.remove(y)\n",
    "#\n",
    "######## For binary classification, response should be a factor  #####\n",
    "#####   train[y] = train[y].asfactor()\n",
    "#####   test[y] = test[y].asfactor()\n",
    "#\n",
    "# http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html\n",
    "# Balance Classes to compensate unbalanced data\n",
    "# Run AutoML for 25 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=25, seed=19, exclude_algos=[\"DRF\",\"GLM\"])\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "#\n",
    "sc.stop()\n",
    "#\n",
    "print(\"Model Training Done!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_212\"; OpenJDK Runtime Environment (build 1.8.0_212-8u212-b03-0ubuntu1.18.04.1-b03); OpenJDK 64-Bit Server VM (build 25.212-b03, mixed mode)\n",
      "  Starting server from /home/joci/anaconda3/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpo8vpllyw\n",
      "  JVM stdout: /tmp/tmpo8vpllyw/h2o_joci_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpo8vpllyw/h2o_joci_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n",
      "Warning: Your H2O cluster version is too old (8 months and 27 days)! Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/GMT</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>8 months and 27 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_joci_127oi9</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.755 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       Etc/GMT\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.1\n",
       "H2O cluster version age:    8 months and 27 days !!!\n",
       "H2O cluster name:           H2O_from_python_joci_127oi9\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.755 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  1\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.7.3 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "import subprocess\n",
    "subprocess.run('unset http_proxy', shell=True)\n",
    "\n",
    "h2o.init(ip=\"localhost\",port=54321)\n",
    "#\n",
    "#\n",
    "# Arguments\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
