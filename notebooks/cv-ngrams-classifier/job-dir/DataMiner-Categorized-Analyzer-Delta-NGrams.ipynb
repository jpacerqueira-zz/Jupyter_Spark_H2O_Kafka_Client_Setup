{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "###### https://github.com/LucaCanali/Miscellaneous/blob/master/Pyspark_SQL_Magic_Jupyter/IPython_Pyspark_SQL_Magic.py\n",
    "#\n",
    "#\n",
    "# IPython magic functions to use with Pyspark and Spark SQL\n",
    "# The following code is intended as examples of shorcuts to simplify the use of SQL in pyspark\n",
    "# The defined functions are:\n",
    "#\n",
    "# %sql <statement>          - return a Spark DataFrame for lazy evaluation of the SQL\n",
    "# %sql_show <statement>     - run the SQL statement and show max_show_lines (50) lines\n",
    "# %sql_display <statement>  - run the SQL statement and display the results using a HTML table \n",
    "#                           - this is implemented passing via Pandas and displays up to max_show_lines (50)\n",
    "# %sql_explain <statement>  - display the execution plan of the SQL statement\n",
    "#\n",
    "# Use: %<magic> for line magic or %%<magic> for cell magic.\n",
    "#\n",
    "# Author: Luca.Canali@cern.ch\n",
    "# September 2016\n",
    "#\n",
    "\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "# Configuration parameters\n",
    "max_show_lines = 50         # Limit on the number of lines to show with %sql_show and %sql_display\n",
    "detailed_explain = True     # Set to False if you want to see only the physical plan when running explain\n",
    "\n",
    "\n",
    "@register_line_cell_magic\n",
    "def sql(line, cell=None):\n",
    "    \"Return a Spark DataFrame for lazy evaluation of the sql. Use: %sql or %%sql\"\n",
    "    val = cell if cell is not None else line \n",
    "    return sqlContext.sql(val)\n",
    "\n",
    "@register_line_cell_magic\n",
    "def sql_show(line, cell=None):\n",
    "    \"Execute sql and show the first max_show_lines lines. Use: %sql_show or %%sql_show\"\n",
    "    val = cell if cell is not None else line \n",
    "    return sqlContext.sql(val).show(max_show_lines) \n",
    "\n",
    "@register_line_cell_magic\n",
    "def sql_display(line, cell=None):\n",
    "    \"\"\"Execute sql and convert results to Pandas DataFrame for pretty display or further processing.\n",
    "    Use: %sql_display or %%sql_display\"\"\"\n",
    "    val = cell if cell is not None else line \n",
    "    return sqlContext.sql(val).limit(max_show_lines).toPandas() \n",
    "\n",
    "@register_line_cell_magic\n",
    "def sql_explain(line, cell=None):\n",
    "    \"Display the execution plan of the sql. Use: %sql_explain or %%sql_explain\"\n",
    "    val = cell if cell is not None else line \n",
    "    return sqlContext.sql(val).explain(detailed_explain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- filename: string (nullable = true)\n",
      " |-- pages: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- p_content: string (nullable = true)\n",
      " |    |    |-- page_n: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- Filename: string (nullable = true)\n",
      " |-- pagei: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 1_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 2_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 3_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 4_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 5_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 6_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 1_counts: vector (nullable = true)\n",
      " |-- 2_counts: vector (nullable = true)\n",
      " |-- 3_counts: vector (nullable = true)\n",
      " |-- 4_counts: vector (nullable = true)\n",
      " |-- 5_counts: vector (nullable = true)\n",
      " |-- 6_counts: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- skill: string (nullable = true)\n",
      " |-- role: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      "\n",
      "Table Loading Done\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "###### Load The Delta   ######\n",
    "##############################\n",
    "###\n",
    "### Input delta in folder :  /data/delta\n",
    "job_dir=\"/home/notebookuser/notebooks/cv-ngrams-classifier/job-dir/\"\n",
    "json_cv_file=job_dir+\"data/delta/json-cv-pdf\"\n",
    "json_cv_table=\"pdf_cv\"\n",
    "#\n",
    "ngrams_cv_file=job_dir+\"data/delta/cv-files-ngrams\"\n",
    "ngrams_cv_table=\"ngrams_cv\"\n",
    "#\n",
    "skills_file=job_dir+\"data/delta/role_skills\"\n",
    "skills_table=\"role_skills\"\n",
    "###\n",
    "######\n",
    "##############################Execution##########################\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "import subprocess\n",
    "#\n",
    "sc = pyspark.SparkContext(appName=\"Daily_CV_Analysis-Delta\")\n",
    "sqlContext = SQLContext(sc)\n",
    "#\n",
    "\n",
    "#\n",
    "# Join with Internal Curation Data in urltopredict staged folder\n",
    "from pyspark.sql import functions as F\n",
    "### use version=1\n",
    "version=1\n",
    "## .option(\"versionAsOf\", version)\n",
    "delta_df1=sqlContext.read.format(\"delta\").load(json_cv_file)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "delta_df1.printSchema()\n",
    "delta_df1.registerTempTable(json_cv_table)\n",
    "#\n",
    "delta_df2=sqlContext.read.format(\"delta\").load(ngrams_cv_file)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "delta_df2.printSchema()\n",
    "delta_df2.registerTempTable(ngrams_cv_table)\n",
    "#\n",
    "delta_df3=sqlContext.read.format(\"delta\").load(skills_file)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "delta_df3.printSchema()\n",
    "delta_df3.registerTempTable(skills_table)\n",
    "#\n",
    "print(\"Table Loading Done\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- filename: string (nullable = true)\n",
      " |-- terms_in_pages: string (nullable = true)\n",
      "\n",
      "+-------------------+-----------------+-----+\n",
      "|           filename|   terms_in_pages|count|\n",
      "+-------------------+-----------------+-----+\n",
      "|Candidate2-AWS_Data|             data|   99|\n",
      "|Candidate4-AWS_Data|             data|   73|\n",
      "|Candidate1-AWS_Data|             data|   70|\n",
      "|Candidate4-AWS_Data|             Data|   70|\n",
      "|Candidate1-AWS_Data|           Oracle|   61|\n",
      "|Candidate1-AWS_Data|             Data|   38|\n",
      "|Candidate2-AWS_Data|             Data|   35|\n",
      "|Candidate4-AWS_Data|           Oracle|   32|\n",
      "|Candidate1-AWS_Data|            using|   31|\n",
      "|Candidate4-AWS_Data|            using|   30|\n",
      "|Candidate2-AWS_Data|           Oracle|   28|\n",
      "|Candidate2-AWS_Data|         business|   27|\n",
      "|Candidate1-AWS_Data|               BI|   22|\n",
      "|Candidate2-AWS_Data|            using|   21|\n",
      "|Candidate3-AWS_Data|           system|   20|\n",
      "|Candidate2-AWS_Data|             team|   18|\n",
      "|Candidate4-AWS_Data|               BI|   18|\n",
      "|Candidate2-AWS_Data|        including|   17|\n",
      "|Candidate4-AWS_Data|          Kimball|   16|\n",
      "|Candidate2-AWS_Data|              AWS|   16|\n",
      "|Candidate4-AWS_Data|         solution|   15|\n",
      "|Candidate4-AWS_Data|     architecture|   15|\n",
      "|Candidate1-AWS_Data|              AWS|   15|\n",
      "|Candidate1-AWS_Data|              SQL|   14|\n",
      "|Candidate1-AWS_Data|              ETL|   14|\n",
      "|Candidate2-AWS_Data|            cloud|   14|\n",
      "|Candidate1-AWS_Data|             into|   13|\n",
      "|Candidate1-AWS_Data|             Name|   13|\n",
      "|Candidate1-AWS_Data|              Big|   13|\n",
      "|Candidate4-AWS_Data|        Architect|   13|\n",
      "|Candidate3-AWS_Data|            using|   13|\n",
      "|Candidate1-AWS_Data|      Designation|   12|\n",
      "|Candidate1-AWS_Data|           Period|   12|\n",
      "|Candidate4-AWS_Data|           design|   12|\n",
      "|Candidate4-AWS_Data|              SQL|   12|\n",
      "|Candidate1-AWS_Data|       Employment|   12|\n",
      "|Candidate2-AWS_Data|              ETL|   12|\n",
      "|Candidate1-AWS_Data|            build|   12|\n",
      "|Candidate1-AWS_Data|          Company|   12|\n",
      "|Candidate4-AWS_Data|        analytics|   11|\n",
      "|Candidate1-AWS_Data|Responsibilities:|   11|\n",
      "|Candidate1-AWS_Data|               UK|   11|\n",
      "|Candidate4-AWS_Data|              new|   11|\n",
      "|Candidate4-AWS_Data|           Markit|   11|\n",
      "|Candidate3-AWS_Data|              AWS|   11|\n",
      "|Candidate1-AWS_Data|          reports|   10|\n",
      "|Candidate4-AWS_Data|         BANKING,|   10|\n",
      "|Candidate1-AWS_Data|             then|   10|\n",
      "|Candidate1-AWS_Data|         Database|   10|\n",
      "|Candidate4-AWS_Data|         business|   10|\n",
      "|Candidate4-AWS_Data|             Lead|   10|\n",
      "|Candidate4-AWS_Data|              EDM|   10|\n",
      "|Candidate3-AWS_Data|                 |   10|\n",
      "|Candidate3-AWS_Data|            Azure|   10|\n",
      "|Candidate4-AWS_Data|          Project|   10|\n",
      "|Candidate2-AWS_Data|         platform|    9|\n",
      "|Candidate4-AWS_Data|           Market|    9|\n",
      "|Candidate4-AWS_Data|       Analytics,|    9|\n",
      "|Candidate4-AWS_Data|               DW|    9|\n",
      "|Candidate3-AWS_Data|               To|    9|\n",
      "|Candidate1-AWS_Data|              OBI|    9|\n",
      "|Candidate1-AWS_Data|             time|    9|\n",
      "|Candidate2-AWS_Data|         solution|    9|\n",
      "|Candidate2-AWS_Data|       ARCHITECT:|    9|\n",
      "|Candidate2-AWS_Data|      application|    9|\n",
      "|Candidate2-AWS_Data|            based|    9|\n",
      "|Candidate3-AWS_Data|            based|    9|\n",
      "|Candidate4-AWS_Data|              AND|    9|\n",
      "|Candidate2-AWS_Data|     Architecture|    9|\n",
      "|Candidate2-AWS_Data|           design|    9|\n",
      "|Candidate2-AWS_Data|             DATA|    9|\n",
      "|Candidate1-AWS_Data|            data.|    9|\n",
      "|Candidate4-AWS_Data|     Architecture|    8|\n",
      "|Candidate2-AWS_Data|                 |    8|\n",
      "|Candidate3-AWS_Data|           Design|    8|\n",
      "|Candidate3-AWS_Data|               MS|    8|\n",
      "|Candidate4-AWS_Data|              AWS|    8|\n",
      "|Candidate3-AWS_Data|          systems|    8|\n",
      "|Candidate1-AWS_Data|            Build|    8|\n",
      "|Candidate4-AWS_Data|        programme|    8|\n",
      "|Candidate3-AWS_Data|        Architect|    8|\n",
      "|Candidate2-AWS_Data|        migration|    8|\n",
      "|Candidate1-AWS_Data|              eBS|    8|\n",
      "|Candidate1-AWS_Data|             like|    8|\n",
      "|Candidate4-AWS_Data|       Consultant|    8|\n",
      "|Candidate2-AWS_Data|              end|    8|\n",
      "|Candidate1-AWS_Data|             Ltd.|    8|\n",
      "|Candidate2-AWS_Data|      management,|    8|\n",
      "|Candidate1-AWS_Data|             This|    8|\n",
      "|Candidate4-AWS_Data|        Warehouse|    8|\n",
      "|Candidate4-AWS_Data|        warehouse|    8|\n",
      "|Candidate1-AWS_Data|            OBIEE|    8|\n",
      "|Candidate4-AWS_Data|             Tech|    8|\n",
      "|Candidate4-AWS_Data|           Global|    8|\n",
      "|Candidate4-AWS_Data|           Server|    8|\n",
      "|Candidate1-AWS_Data|         business|    8|\n",
      "|Candidate4-AWS_Data|            ASSET|    8|\n",
      "|Candidate1-AWS_Data|         Projects|    7|\n",
      "|Candidate2-AWS_Data|     requirements|    7|\n",
      "|Candidate2-AWS_Data|              SQL|    7|\n",
      "|Candidate1-AWS_Data|            Cloud|    7|\n",
      "|Candidate2-AWS_Data|         Business|    7|\n",
      "|Candidate1-AWS_Data|            Agile|    7|\n",
      "|Candidate4-AWS_Data|       Orchestria|    7|\n",
      "|Candidate2-AWS_Data|        designing|    7|\n",
      "|Candidate2-AWS_Data|        solutions|    7|\n",
      "|Candidate4-AWS_Data|             OPEN|    7|\n",
      "|Candidate1-AWS_Data|           Hadoop|    7|\n",
      "|Candidate4-AWS_Data|        solutions|    7|\n",
      "|Candidate3-AWS_Data|        Microsoft|    7|\n",
      "|Candidate1-AWS_Data|              end|    7|\n",
      "|Candidate3-AWS_Data|           Senior|    7|\n",
      "|Candidate1-AWS_Data|           Client|    7|\n",
      "|Candidate2-AWS_Data|         Designed|    7|\n",
      "|Candidate1-AWS_Data|    Forms/Reports|    7|\n",
      "|Candidate4-AWS_Data|         Produced|    7|\n",
      "|Candidate4-AWS_Data|              key|    7|\n",
      "|Candidate4-AWS_Data|        Bloomberg|    7|\n",
      "|Candidate1-AWS_Data|                 |    7|\n",
      "|Candidate2-AWS_Data|              Big|    7|\n",
      "|Candidate1-AWS_Data|            Forms|    7|\n",
      "|Candidate2-AWS_Data|           PL/SQL|    7|\n",
      "|Candidate4-AWS_Data|           portal|    7|\n",
      "|Candidate1-AWS_Data|            which|    7|\n",
      "|Candidate1-AWS_Data|          Reports|    7|\n",
      "|Candidate1-AWS_Data|        reporting|    7|\n",
      "|Candidate1-AWS_Data|          Created|    7|\n",
      "|Candidate3-AWS_Data|             Team|    7|\n",
      "|Candidate4-AWS_Data|       Enterprise|    7|\n",
      "|Candidate2-AWS_Data|              11g|    7|\n",
      "|Candidate2-AWS_Data|          reports|    7|\n",
      "|Candidate4-AWS_Data|           Senior|    7|\n",
      "|Candidate1-AWS_Data|           worked|    7|\n",
      "|Candidate2-AWS_Data|       Enterprise|    6|\n",
      "|Candidate2-AWS_Data|      performance|    6|\n",
      "|Candidate4-AWS_Data|           ORACLE|    6|\n",
      "|Candidate3-AWS_Data|          Provide|    6|\n",
      "|Candidate1-AWS_Data|       Experience|    6|\n",
      "+-------------------+-----------------+-----+\n",
      "only showing top 138 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "####\n",
    "#### Expose most frequent Terms in CV pages\n",
    "####\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "#\n",
    "mywords=sqlContext.sql(\"select filename,pages from pdf_cv where filename IS NOT NULL \") ## ='cv-x1' \n",
    "mywords=mywords.select(\"filename\",explode(\"pages.p_content\").alias(\"p_cont\"))\\\n",
    ".select(\"filename\",explode(split(col(\"p_cont\"), \"\\s+\")).alias(\"terms_in_pages\"))\n",
    "###\n",
    "mywords.printSchema()\n",
    "####\n",
    "filler_words_list=['the','a','of','to','is','or','in','on','for','by','an','The','and','A','at',\\\n",
    "                   'your','as','that','when','their','it','be','with','you','are','It','from','can','usually',\\\n",
    "                   '--','-',':','•','|','●','§','&','–','.','_',';',',','(',')','/',\\\n",
    "                   '1','2','3','4','5','6','7','8','9','0',\\\n",
    "                   'a','b','c','d','e','f','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',\\\n",
    "                   ' ','\\n','\\n ','  ','\\n  ','   ','\\n   ','    ','     ','      ','       ','        ','         ','          ','           ']\n",
    "####\n",
    "wordCountDF = mywords.filter(~(col(\"terms_in_pages\").isin(filler_words_list))).groupBy(\"filename\",\"terms_in_pages\").count().orderBy(col('count').desc())\n",
    "####        \n",
    "wordCountDF.show(138)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- filename: string (nullable = true)\n",
      " |-- pages: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- p_content: string (nullable = true)\n",
      " |    |    |-- page_n: string (nullable = true)\n",
      "\n",
      "+-------------------+--------------------+\n",
      "|           filename|               pages|\n",
      "+-------------------+--------------------+\n",
      "|Candidate4-AWS_Data|[[PAUL VENABLES T...|\n",
      "|Candidate3-AWS_Data|[[ Daniel C. Dora...|\n",
      "|Candidate1-AWS_Data|[[ Abhijit Jadhav...|\n",
      "|Candidate2-AWS_Data|[[ Masood Ahmad  ...|\n",
      "+-------------------+--------------------+\n",
      "\n",
      "root\n",
      " |-- Filename: string (nullable = true)\n",
      " |-- pagei: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 1_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 2_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 3_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 4_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 5_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 6_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 1_counts: vector (nullable = true)\n",
      " |-- 2_counts: vector (nullable = true)\n",
      " |-- 3_counts: vector (nullable = true)\n",
      " |-- 4_counts: vector (nullable = true)\n",
      " |-- 5_counts: vector (nullable = true)\n",
      " |-- 6_counts: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|           Filename|               pagei|             1_grams|             2_grams|             3_grams|             4_grams|             5_grams|             6_grams|            1_counts|            2_counts|            3_counts|            4_counts|            5_counts|            6_counts|            features|\n",
      "+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Candidate4-AWS_Data|[paul, venables, ...|[paul, venables, ...|[paul venables, v...|[paul venables te...|[paul venables te...|[paul venables te...|[paul venables te...|(2463,[0,1,2,3,4,...|(8506,[0,1,2,3,5,...|(10541,[0,2,4,6,7...|(10978,[1,2,3,4,6...|(11096,[0,2,3,4,5...|(11136,[0,1,2,3,4...|(54720,[0,1,2,3,4...|\n",
      "|Candidate4-AWS_Data|[paul, venables, ...|[paul, venables, ...|[paul venables, v...|[paul venables te...|[paul venables te...|[paul venables te...|[paul venables te...|(2463,[0,1,2,3,4,...|(8506,[0,1,2,3,5,...|(10541,[3,4,6,7,9...|(10978,[1,2,3,4,6...|(11096,[0,2,3,4,5...|(11136,[0,1,2,3,4...|(54720,[0,1,2,3,4...|\n",
      "|Candidate4-AWS_Data|[paul, venables, ...|[paul, venables, ...|[paul venables, v...|[paul venables te...|[paul venables te...|[paul venables te...|[paul venables te...|(2463,[0,1,2,3,4,...|(8506,[0,1,5,6,7,...|(10541,[2,4,6,9,1...|(10978,[1,2,3,4,6...|(11096,[0,2,3,4,5...|(11136,[0,1,2,3,4...|(54720,[0,1,2,3,4...|\n",
      "|Candidate4-AWS_Data|[paul, venables, ...|[paul, venables, ...|[paul venables, v...|[paul venables te...|[paul venables te...|[paul venables te...|[paul venables te...|(2463,[0,1,2,3,4,...|(8506,[0,1,3,9,11...|(10541,[2,4,6,9,1...|(10978,[1,2,3,4,6...|(11096,[0,2,3,4,5...|(11136,[0,1,2,3,4...|(54720,[0,1,2,3,4...|\n",
      "|Candidate4-AWS_Data|[paul, venables, ...|[paul, venables, ...|[paul venables, v...|[paul venables te...|[paul venables te...|[paul venables te...|[paul venables te...|(2463,[0,1,5,6,9,...|(8506,[1,2,3,4,5,...|(10541,[4,6,7,9,1...|(10978,[1,2,3,4,6...|(11096,[0,2,3,4,5...|(11136,[0,1,2,3,4...|(54720,[0,1,5,6,9...|\n",
      "+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "root\n",
      " |-- skill: string (nullable = true)\n",
      " |-- role: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      "\n",
      "+------+-------------+-----+\n",
      "| skill|         role|level|\n",
      "+------+-------------+-----+\n",
      "|python|data engineer|    2|\n",
      "|python|data engineer|    3|\n",
      "|python|data engineer|    4|\n",
      "|python|data engineer|    5|\n",
      "| scala|data engineer|    3|\n",
      "+------+-------------+-----+\n",
      "\n",
      "root\n",
      " |-- filename: string (nullable = true)\n",
      "\n",
      "+-------------------+\n",
      "|           filename|\n",
      "+-------------------+\n",
      "|Candidate3-AWS_Data|\n",
      "|Candidate1-AWS_Data|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "data_analytics_df1=sqlContext.sql(\"select * from pdf_cv limit 5\")\n",
    "data_analytics_df1.printSchema()\n",
    "data_analytics_df1.show(5)\n",
    "#\n",
    "#\n",
    "data_analytics_df2=sqlContext.sql(\"select * from ngrams_cv limit 5\")\n",
    "data_analytics_df2.printSchema()\n",
    "data_analytics_df2.show(5)\n",
    "#\n",
    "#\n",
    "data_analytics_df3=sqlContext.sql(\"select * from role_skills limit 5\")\n",
    "data_analytics_df3.printSchema()\n",
    "data_analytics_df3.show(5)\n",
    "#\n",
    "#\n",
    "data_analytics_df4=sqlContext.sql(\" select distinct(a.filename) from ngrams_cv as a, role_skills as b where b.role = 'devops engineer' AND b.level='5' AND b.skill = 'terraform' AND (array_contains(a.1_grams,b.skill)) limit 10 \")\n",
    "data_analytics_df4.printSchema()\n",
    "data_analytics_df4.show(5)\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Candidate3-AWS_Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Candidate1-AWS_Data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename\n",
       "0  Candidate3-AWS_Data\n",
       "1  Candidate1-AWS_Data"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql_display\n",
    "select distinct(a.filename) from ngrams_cv as a, role_skills as b \n",
    " where b.role = 'devops engineer' AND b.level='5' AND b.skill = 'terraform' \n",
    "  AND (array_contains(a.1_grams,b.skill)) limit 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
